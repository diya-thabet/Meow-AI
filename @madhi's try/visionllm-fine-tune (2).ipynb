{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14537279,"sourceType":"datasetVersion","datasetId":9284898},{"sourceId":292551858,"sourceType":"kernelVersion"},{"sourceId":292574694,"sourceType":"kernelVersion"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Install with Version Pinning\n# We force trl to be <0.13 to avoid the \"ValueError: dataset appears to be vision-related\" bug\n!pip install -q \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n!pip install -q --no-deps \"trl<0.13\" peft accelerate bitsandbytes triton xformers\n\nimport torch\nprint(f\"GPU Available: {torch.cuda.is_available()}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-18T18:11:29.377897Z","iopub.execute_input":"2026-01-18T18:11:29.378222Z","iopub.status.idle":"2026-01-18T18:11:46.065477Z","shell.execute_reply.started":"2026-01-18T18:11:29.378189Z","shell.execute_reply":"2026-01-18T18:11:46.064684Z"}},"outputs":[{"name":"stdout","text":"  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nGPU Available: True\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport json\nimport torch\nfrom pathlib import Path\nfrom PIL import Image\nfrom unsloth import FastVisionModel, UnslothVisionDataCollator\nfrom trl import SFTTrainer, SFTConfig\nfrom datasets import Dataset\n\n# --- YOUR SPECIFIC PATHS ---\nINPUT_DIR = \"/kaggle/input/raf-au/aligned\"\nEMOLABEL_FILE = \"/kaggle/input/raf-au/RAFCE_emolabel.txt\"\nPARTITION_FILE = \"/kaggle/input/raf-au/RAFCE_partition.txt\"\nAU_FILE = \"/kaggle/input/raf-au/RAFCE_AUlabel.txt\"\n\n# Output Directory (Working Directory)\nOUTPUT_DIR = \"/kaggle/working/qwen_fer_output\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# --- MODEL CONFIG ---\n# Using 7B as per your \"AI_note_1.pdf\" recommendation for micro-expressions\nMODEL_ID = \"unsloth/Qwen2-VL-7B-Instruct\" \nMAX_SEQ_LENGTH = 2048\nLORA_RANK = 32\nLORA_ALPHA = 64","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T18:16:01.560190Z","iopub.execute_input":"2026-01-18T18:16:01.560514Z","iopub.status.idle":"2026-01-18T18:16:01.565952Z","shell.execute_reply.started":"2026-01-18T18:16:01.560482Z","shell.execute_reply":"2026-01-18T18:16:01.565225Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"AU Logic (The \"Reasoning\" Engine)","metadata":{}},{"cell_type":"code","source":"# ==========================================\n# CELL 3: METADATA & EXPLANATION GENERATOR\n# ==========================================\n# 1. Maps\nEMOTION_MAP = {\n    1: 'Happily Surprised', 2: 'Happily Disgusted', 3: 'Sadly Fearful',\n    4: 'Sadly Angry', 5: 'Sadly Surprised', 6: 'Sadly Disgusted',\n    7: 'Fearfully Angry', 8: 'Fearfully Surprised', 9: 'Fearfully Disgusted',\n    10: 'Angrily Surprised', 11: 'Angrily Disgusted', 12: 'Disgustedly Surprised',\n    13: 'Happily Fearful', 14: 'Happily Sad'\n}\n\nAU_MAP = {\n    '1': 'Inner Brow Raiser', '2': 'Outer Brow Raiser', '4': 'Brow Lowerer',\n    '5': 'Upper Lid Raiser', '6': 'Cheek Raiser', '7': 'Lid Tightener',\n    '9': 'Nose Wrinkler', '10': 'Upper Lip Raiser', '12': 'Lip Corner Puller',\n    '15': 'Lip Corner Depressor', '16': 'Lower Lip Depressor', '20': 'Lip Stretcher',\n    '23': 'Lip Tightener', '25': 'Lips Part', '26': 'Jaw Drop', '27': 'Mouth Stretch'\n}\n\ndef decode_aus(au_string):\n    if not isinstance(au_string, str) or au_string == \"null\": return \"\"\n    codes = au_string.split()\n    descriptions = [f\"{AU_MAP.get(c, '')} (AU{c})\" for c in codes if c in AU_MAP]\n    return \", \".join(descriptions)\n\ndef prepare_raw_data():\n    print(\"üìñ Reading Metadata...\")\n    df_label = pd.read_csv(EMOLABEL_FILE, sep=r'\\s+', header=None, names=['filename', 'label_id'])\n    df_part = pd.read_csv(PARTITION_FILE, sep=r'\\s+', header=None, names=['filename', 'split_id'])\n    df = pd.merge(df_label, df_part, on='filename')\n    \n    if os.path.exists(AU_FILE):\n        with open(AU_FILE, 'r') as f:\n            au_dict = {l.split()[0]: \" \".join(l.split()[1:]) for l in f.readlines()}\n        df['aus'] = df['filename'].map(au_dict)\n    else:\n        df['aus'] = \"null\"\n\n    # Filter for Train (0 or 1)\n    train_code = 0 if 0 in df['split_id'].unique() else 1\n    train_df = df[df['split_id'] == train_code]\n    print(f\"‚öôÔ∏è Processing {len(train_df)} images...\")\n    \n    raw_list = []\n    for _, row in train_df.iterrows():\n        # Resolve Path\n        img_path = os.path.join(INPUT_DIR, row['filename'])\n        if not os.path.exists(img_path):\n             img_path = os.path.join(INPUT_DIR, row['filename'].replace(\".jpg\", \"_aligned.jpg\"))\n             if not os.path.exists(img_path): continue\n        \n        # Build Explanation Text\n        emo_text = EMOTION_MAP.get(row['label_id'], \"Unknown\")\n        au_desc = decode_aus(row['aus'])\n        explanation = f\"The expression is {emo_text}. I observe: {au_desc}.\" if au_desc else f\"The expression is {emo_text}.\"\n\n        # Just store raw info, don't format messages yet\n        raw_list.append({\n            \"img_path\": img_path,\n            \"explanation\": explanation\n        })\n        \n    return raw_list\n\nraw_data_list = prepare_raw_data()\nprint(f\"‚úÖ Found {len(raw_data_list)} valid samples.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T18:18:37.075918Z","iopub.execute_input":"2026-01-18T18:18:37.076568Z","iopub.status.idle":"2026-01-18T18:18:37.283822Z","shell.execute_reply.started":"2026-01-18T18:18:37.076535Z","shell.execute_reply":"2026-01-18T18:18:37.283210Z"}},"outputs":[{"name":"stdout","text":"üìñ Reading Metadata...\n‚öôÔ∏è Processing 2709 images...\n‚úÖ Found 2709 valid samples.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ==========================================\n# CELL 4: LOAD MODEL & FORMAT DATASET\n# ==========================================\nfrom datasets import Dataset\n\n# 1. Load Model\nprint(\"ü§ñ Loading Qwen2-VL-7B...\")\nmodel, tokenizer = FastVisionModel.from_pretrained(\n    MODEL_ID,\n    load_in_4bit=True,\n    use_gradient_checkpointing=\"unsloth\", \n)\n\n# 2. Apply LoRA\nmodel = FastVisionModel.get_peft_model(\n    model,\n    finetune_vision_layers=True, \n    finetune_language_layers=True,\n    finetune_attention_modules=True,\n    finetune_mlp_modules=True,\n    r=LORA_RANK,\n    lora_alpha=LORA_ALPHA,\n    lora_dropout=0,\n    bias=\"none\",\n    random_state=3407,\n    use_rslora=False,\n)\n\n# 3. THE FIX: Format Function that inserts the Image Object\ndef format_for_unsloth(example):\n    # Load the image into memory\n    try:\n        image = Image.open(example['img_path']).convert(\"RGB\")\n    except:\n        return None # Skip broken images\n    \n    # Structure EXACTLY how Unsloth Qwen2-VL expects it\n    # It needs: {\"type\": \"image\", \"image\": <PIL_Image_Object>}\n    return {\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"image\", \"image\": image},  # <--- THIS WAS MISSING\n                    {\"type\": \"text\", \"text\": \"Classify the compound emotion and explain the facial cues.\"}\n                ]\n            },\n            {\n                \"role\": \"assistant\",\n                \"content\": [\n                    {\"type\": \"text\", \"text\": example['explanation']}\n                ]\n            }\n        ]\n    }\n\n# 4. Create and Map Dataset\nprint(\"üîÑ Formatting Dataset (Loading images into cache)...\")\ntrain_dataset = Dataset.from_list(raw_data_list)\n# We map the function to create the 'messages' column with real images\ntrain_dataset = train_dataset.map(format_for_unsloth, remove_columns=[\"img_path\", \"explanation\"])\n\nprint(f\"‚úÖ Dataset Ready! Sample keys: {train_dataset[0]['messages'][0]['content'][0].keys()}\")\n# Should print: dict_keys(['type', 'image']) -> This proves the fix working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T18:18:47.430619Z","iopub.execute_input":"2026-01-18T18:18:47.431396Z","iopub.status.idle":"2026-01-18T18:20:24.189748Z","shell.execute_reply.started":"2026-01-18T18:18:47.431355Z","shell.execute_reply":"2026-01-18T18:20:24.189135Z"}},"outputs":[{"name":"stdout","text":"ü§ñ Loading Qwen2-VL-7B...\n==((====))==  Unsloth 2026.1.3: Fast Qwen2_Vl patching. Transformers: 4.57.1.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"name":"stderr","text":"The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Making `model.base_model.model.model.visual` require gradients\nüîÑ Formatting Dataset (Loading images into cache)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2709 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f8ebef00dd24c458d5c2b7c9b7a2519"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Dataset Ready! Sample keys: dict_keys(['image', 'text', 'type'])\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Cell 5: Training (Updated config to bypass VLM check)\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    data_collator=UnslothVisionDataCollator(model, tokenizer),\n    train_dataset=train_dataset,\n    args=SFTConfig(\n        per_device_train_batch_size=2,\n        gradient_accumulation_steps=4,\n        max_steps=1500,\n        warmup_steps=50,\n        learning_rate=2e-4,\n        fp16=True,\n        bf16=False,\n        gradient_checkpointing=True,\n        optim=\"adamw_8bit\",\n        logging_steps=10,\n        output_dir=OUTPUT_DIR,\n        save_strategy=\"steps\",\n        save_steps=200,\n        report_to=\"none\",\n        \n        # --- THE FIX FOR \"ValueError: dataset appears vision-related\" ---\n        remove_unused_columns=False, \n        dataset_text_field=\"\", \n        dataset_kwargs={\"skip_prepare_dataset\": True}, # Stops TRL from analyzing columns\n    ),\n)\n\nprint(\"üöÄ Starting Training...\")\ntrainer_stats = trainer.train()\n\n# Save Result\nmodel.save_pretrained(f\"{OUTPUT_DIR}/final_model\")\ntokenizer.save_pretrained(f\"{OUTPUT_DIR}/final_model\")\nprint(f\"üíæ Model Saved to {OUTPUT_DIR}/final_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T18:22:04.864990Z","iopub.execute_input":"2026-01-18T18:22:04.865702Z","iopub.status.idle":"2026-01-18T20:08:20.779840Z","shell.execute_reply.started":"2026-01-18T18:22:04.865666Z","shell.execute_reply":"2026-01-18T20:08:20.778861Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Model does not have a default image size - using 512\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/working/unsloth_compiled_cache/UnslothSFTTrainer.py:873: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\nThe model is already on multiple devices. Skipping the move to device specified in `args`.\n","output_type":"stream"},{"name":"stdout","text":"üöÄ Starting Training...\n","output_type":"stream"},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 2,709 | Num Epochs = 5 | Total steps = 1,500\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n \"-____-\"     Trainable parameters = 101,711,872 of 8,393,087,488 (1.21% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1500/1500 1:45:12, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>3.861300</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.595700</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.193000</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.193700</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.093400</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.081000</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.083000</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.070900</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.070000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.070300</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.063000</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.073900</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.072800</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.065600</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.061500</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.071000</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.055700</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.059700</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.072300</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.053700</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.053500</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.056600</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.046700</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.065200</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.057900</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.054700</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.055700</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.057900</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.057400</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.059000</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.050900</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.046600</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.043100</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.053300</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.040400</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.040100</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.045900</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.041300</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.049300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.050500</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.050500</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.032700</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.041800</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.046900</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.048000</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.039900</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.037700</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.041200</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.044200</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.040300</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.042600</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.040700</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.044600</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.046700</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.042400</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.041300</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.042800</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.049400</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.039700</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.052700</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.042000</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.044800</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.041400</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.041800</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.046100</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.035200</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.032600</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.040400</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.033600</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.025700</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.025900</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.027400</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.033300</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.029100</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.019200</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.026900</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.024500</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.020500</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.030900</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.025900</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.028900</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.027300</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.027900</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.026900</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.025500</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.031300</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.028000</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.023900</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>0.022100</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.034300</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>0.031900</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.028500</td>\n    </tr>\n    <tr>\n      <td>930</td>\n      <td>0.025900</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>0.027700</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.024800</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>0.027100</td>\n    </tr>\n    <tr>\n      <td>970</td>\n      <td>0.027500</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>0.028000</td>\n    </tr>\n    <tr>\n      <td>990</td>\n      <td>0.023700</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.025800</td>\n    </tr>\n    <tr>\n      <td>1010</td>\n      <td>0.041300</td>\n    </tr>\n    <tr>\n      <td>1020</td>\n      <td>0.024600</td>\n    </tr>\n    <tr>\n      <td>1030</td>\n      <td>0.016900</td>\n    </tr>\n    <tr>\n      <td>1040</td>\n      <td>0.012800</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.019900</td>\n    </tr>\n    <tr>\n      <td>1060</td>\n      <td>0.016200</td>\n    </tr>\n    <tr>\n      <td>1070</td>\n      <td>0.016500</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>0.015800</td>\n    </tr>\n    <tr>\n      <td>1090</td>\n      <td>0.016800</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.012100</td>\n    </tr>\n    <tr>\n      <td>1110</td>\n      <td>0.011200</td>\n    </tr>\n    <tr>\n      <td>1120</td>\n      <td>0.014300</td>\n    </tr>\n    <tr>\n      <td>1130</td>\n      <td>0.016900</td>\n    </tr>\n    <tr>\n      <td>1140</td>\n      <td>0.011900</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.010700</td>\n    </tr>\n    <tr>\n      <td>1160</td>\n      <td>0.013700</td>\n    </tr>\n    <tr>\n      <td>1170</td>\n      <td>0.009100</td>\n    </tr>\n    <tr>\n      <td>1180</td>\n      <td>0.013200</td>\n    </tr>\n    <tr>\n      <td>1190</td>\n      <td>0.018000</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.012800</td>\n    </tr>\n    <tr>\n      <td>1210</td>\n      <td>0.013200</td>\n    </tr>\n    <tr>\n      <td>1220</td>\n      <td>0.007200</td>\n    </tr>\n    <tr>\n      <td>1230</td>\n      <td>0.018000</td>\n    </tr>\n    <tr>\n      <td>1240</td>\n      <td>0.013300</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.011600</td>\n    </tr>\n    <tr>\n      <td>1260</td>\n      <td>0.015000</td>\n    </tr>\n    <tr>\n      <td>1270</td>\n      <td>0.013700</td>\n    </tr>\n    <tr>\n      <td>1280</td>\n      <td>0.011600</td>\n    </tr>\n    <tr>\n      <td>1290</td>\n      <td>0.011100</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.009900</td>\n    </tr>\n    <tr>\n      <td>1310</td>\n      <td>0.009000</td>\n    </tr>\n    <tr>\n      <td>1320</td>\n      <td>0.009900</td>\n    </tr>\n    <tr>\n      <td>1330</td>\n      <td>0.012700</td>\n    </tr>\n    <tr>\n      <td>1340</td>\n      <td>0.013900</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.013000</td>\n    </tr>\n    <tr>\n      <td>1360</td>\n      <td>0.008200</td>\n    </tr>\n    <tr>\n      <td>1370</td>\n      <td>0.006600</td>\n    </tr>\n    <tr>\n      <td>1380</td>\n      <td>0.007800</td>\n    </tr>\n    <tr>\n      <td>1390</td>\n      <td>0.006200</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.006300</td>\n    </tr>\n    <tr>\n      <td>1410</td>\n      <td>0.005900</td>\n    </tr>\n    <tr>\n      <td>1420</td>\n      <td>0.003000</td>\n    </tr>\n    <tr>\n      <td>1430</td>\n      <td>0.003400</td>\n    </tr>\n    <tr>\n      <td>1440</td>\n      <td>0.004800</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.004300</td>\n    </tr>\n    <tr>\n      <td>1460</td>\n      <td>0.004400</td>\n    </tr>\n    <tr>\n      <td>1470</td>\n      <td>0.004500</td>\n    </tr>\n    <tr>\n      <td>1480</td>\n      <td>0.003300</td>\n    </tr>\n    <tr>\n      <td>1490</td>\n      <td>0.004900</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.006400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"üíæ Model Saved to /kaggle/working/qwen_fer_output/final_model\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Enable Inference Mode\nFastVisionModel.for_inference(model)\n\ndef predict_emotion(image_path):\n    image = Image.open(image_path).convert(\"RGB\")\n    messages = [\n        {\"role\": \"user\", \"content\": [\n            {\"type\": \"image\"},\n            {\"type\": \"text\", \"text\": \"Classify the compound emotion and explain the facial cues.\"}\n        ]}\n    ]\n    \n    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n    inputs = tokenizer(\n        image,\n        input_text,\n        add_special_tokens=False,\n        return_tensors=\"pt\",\n    ).to(\"cuda\")\n\n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_new_tokens=128,\n            use_cache=True,\n            \n            # --- STRICT SETTINGS ---\n            temperature=0.1, # Forces deterministic classification\n            top_p=0.9,\n            do_sample=True,\n        )\n    \n    return tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"assistant\")[-1].strip()\n\n# Test on a random image from dataset\nimport random\n\n# Use 'raw_data_list' (the variable we created in the fixed Cell 3)\ntest_sample = random.choice(raw_data_list)\n\nprint(f\"üñºÔ∏è Testing Image: {test_sample['img_path']}\")\nprint(f\"üìù Ground Truth: {test_sample['explanation']}\")\n\n# Run prediction\nprediction = predict_emotion(test_sample['img_path'])\nprint(f\"ü§ñ Prediction: {prediction}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T20:12:46.678605Z","iopub.execute_input":"2026-01-18T20:12:46.679026Z","iopub.status.idle":"2026-01-18T20:13:00.621682Z","shell.execute_reply.started":"2026-01-18T20:12:46.678993Z","shell.execute_reply":"2026-01-18T20:13:00.620863Z"}},"outputs":[{"name":"stdout","text":"üñºÔ∏è Testing Image: /kaggle/input/raf-au/aligned/0453_aligned.jpg\nüìù Ground Truth: The expression is Angrily Surprised.\nü§ñ Prediction: The expression is Angrily Surprised.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ==========================================\n# FORCE DOWNLOAD LINK\n# ==========================================\nfrom IPython.display import FileLink\n\n# 1. Make sure the zip exists\nimport os\nzip_filename = \"fer_model_zip.zip\"\nif os.path.exists(zip_filename):\n    print(f\"‚úÖ Found {zip_filename} ({os.path.getsize(zip_filename)/1024/1024:.2f} MB)\")\n    print(\"üëá Click the link below to download:\")\n    \n    # 2. Generate the clickable link\n    display(FileLink(zip_filename))\nelse:\n    print(\"‚ùå Zip file not found! Did you run the 'shutil.make_archive' code above?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T20:33:53.352681Z","iopub.execute_input":"2026-01-18T20:33:53.353293Z","iopub.status.idle":"2026-01-18T20:33:53.360312Z","shell.execute_reply.started":"2026-01-18T20:33:53.353257Z","shell.execute_reply":"2026-01-18T20:33:53.359513Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Found fer_model_zip.zip (363.39 MB)\nüëá Click the link below to download:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/fer_model_zip.zip","text/html":"<a href='fer_model_zip.zip' target='_blank'>fer_model_zip.zip</a><br>"},"metadata":{}}],"execution_count":15}]}