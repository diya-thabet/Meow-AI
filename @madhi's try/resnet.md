√âtude de R√©f√©rence : Limites du ResNet50 sur les √âmotions Compos√©es (RAF-CE)Ce document d√©taille la phase exp√©rimentale "Baseline" du projet de d√©tection d'√©motions compos√©es. L'objectif √©tait d'√©valuer la capacit√© d'une architecture CNN standard (ResNet50) √† g√©n√©raliser sur le jeu de donn√©es RAF-CE (Real-world Affective Faces - Compound Expressions), connu pour sa complexit√© et son d√©s√©quilibre de classes.Ces exp√©riences servent de justification scientifique pour la transition vers des mod√®les multimodaux de raisonnement (Vision-LLMs).üìã R√©sum√© Ex√©cutifExp√©rienceApprocheAccuracy (Val)Gap (Train-Val)VerdictRun 1Baseline (Non-fig√©)43%~44%Sur-ajustement Massif (Overfitting)Run 2Mixup + Gel partiel36%~10%Sous-ajustement (Underfitting)Run 3Fine-Tuning Diff√©rentiel31%N/AOubli Catastrophique (Destabilisation)Conclusion Principale : Le ResNet50 a √©chou√© √† converger vers une solution g√©n√©ralisable. Il oscille entre la m√©morisation pure (pixels) et l'incapacit√© √† apprendre des traits s√©mantiques complexes (micro-expressions), justifiant l'abandon des CNN purs pour cette t√¢che.üõ†Ô∏è Protocole Exp√©rimentalMod√®le : ResNet50 (pr√©-entra√Æn√© sur ImageNet).Donn√©es : RAF-CE (11 classes d'√©motions compos√©es, ex: Happily_Surprised, Fearfully_Angry).Mat√©riel : Kaggle T4 GPU (x2).M√©triques : Accuracy, F1-Score (Macro), Matrice de Confusion.üî¨ Analyse D√©taill√©e des Exp√©riences1. Approche "Na√Øve" (Baseline)Configuration : Mod√®le enti√®rement d√©gel√©, augmentation standard, CrossEntropyLoss.Observation : L'accuracy d'entra√Ænement a atteint 87% tandis que la validation a plafonn√© √† 43%.Interpr√©tation (Overfitting) : Le mod√®le a m√©moris√© le bruit de fond, l'√©clairage et des pixels sp√©cifiques des images d'entra√Ænement au lieu d'apprendre les caract√©ristiques faciales.Preuve XAI (Grad-CAM) : Les cartes de chaleur montraient souvent une activation sur l'arri√®re-plan ou les cheveux plut√¥t que sur les muscles faciaux (yeux/bouche).2. Approche "R√©gularis√©e" (Mixup + Freezing)Configuration : Utilisation de Mixup (m√©lange d'images), gel des couches 1 √† 3 (Feature Extractors), Dropout √©lev√© (0.6).Observation : L'√©cart entre Train et Validation s'est r√©duit √† ~10%, mais la performance globale a chut√© √† 36%.Interpr√©tation (Underfitting) : En emp√™chant la m√©morisation (via Mixup) et en limitant la capacit√© du mod√®le (Gel des couches), nous avons rendu le mod√®le "honn√™te" mais "limit√©". Les features g√©n√©riques d'ImageNet (formes simples) ne suffisent pas pour distinguer des concepts subtils comme Happily Disgusted.3. Approche "Fine-Tuning Avanc√©"Configuration : D√©gel des couches 3 et 4, Taux d'apprentissage diff√©rentiels (1e-5 pour le corps, 1e-3 pour la t√™te).Observation : L'accuracy a chut√© √† 31%, pire que les essais pr√©c√©dents.Interpr√©tation (Oubli Catastrophique) : En autorisant la modification des poids profonds sur un dataset petit et bruit√© ("noisy"), le mod√®le a d√©truit ses connaissances pr√©-entra√Æn√©es. Au lieu d'affiner sa vision, le bruit des donn√©es a corrompu les d√©tecteurs de formes existants.üìä Visualisations et PreuvesMatrice de Confusion (Run 1 - Meilleur Mod√®le)(Ins√©rez ici votre image resnet_final_confusion_matrix.png)Analyse :Biais des classes majoritaires : Le mod√®le pr√©dit correctement les classes simples (Happily_Surprised) mais √©choue totalement sur les classes complexes et rares (Angrily_Disgusted), comme le montre le score F1-Macro tr√®s bas (~0.27).Confusion S√©mantique : Le mod√®le confond souvent des √©motions partageant une caract√©ristique g√©om√©trique √©vidente (ex: bouche ouverte) sans analyser le contexte (yeux fronc√©s vs yeux grands ouverts).üöÄ Conclusion Scientifique & TransitionCette √©tude de r√©f√©rence d√©montre une limitation fondamentale des architectures CNN standard pour la reconnaissance d'√©motions compos√©es sur de petits jeux de donn√©es :Limitation Pixel vs Concept : Le ResNet voit des grilles de pixels, pas des concepts. Il ne peut pas "raisonner" sur le fait qu'un visage a des yeux tristes mais une bouche souriante.Paradoxe Capacit√©-Donn√©es : Sans millions d'images, un CNN profond ne peut pas apprendre ces micro-features sans sur-apprendre (overfitting) ou d√©truire ses poids (catastrophic forgetting).Prochaine √âtape (Notebook 4) :Ces r√©sultats justifient l'utilisation d'un Vision-LLM (ex: Qwen2-VL). Contrairement au ResNet, un V-LLM poss√®de d√©j√† une compr√©hension s√©mantique du monde et utilise le raisonnement (Chain-of-Thought) pour analyser les micro-expressions, contournant ainsi les limitations observ√©es ici.üíª Reproduction des R√©sultatsPour reproduire ces exp√©riences :Ouvrez le Notebook Project_ResNet_Training.ipynb.Assurez-vous que le dataset dataset_resnet_224.zip est attach√©.Ex√©cutez les cellules s√©quentiellement.Les poids du meilleur mod√®le (~43%) sont sauvegard√©s sous best_resnet50.pth